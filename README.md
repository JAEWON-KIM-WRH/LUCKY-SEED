# ğŸŒ± Lucky-Seed: AI ê°“ìƒ ê°€ì± 

> **ML + DL ê¸°ë°˜ ë¯¸ì…˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜ & ê°“ìƒ ê°€ì±  ê²Œì„í™” ì‹œìŠ¤í…œ**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1+-orange.svg)](https://pytorch.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-green.svg)](https://scikit-learn.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.32+-red.svg)](https://streamlit.io)

---

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

**Lucky-Seed**ëŠ” 2030 ì„¸ëŒ€ì˜ ìê¸°ê³„ë°œ í”¼ë¡œê° ë¬¸ì œë¥¼ **ê°€ì± (ë½‘ê¸°) ë©”ì¹´ë‹‰**ê³¼ **AI ë¶„ë¥˜ ëª¨ë¸**ë¡œ í•´ê²°í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

**í•µì‹¬ ML/DL ê³¼ì œ**: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ììœ  í˜•ì‹ì˜ ë¯¸ì…˜ í…ìŠ¤íŠ¸ë¥¼ 5ê°œ ì¹´í…Œê³ ë¦¬(ê±´ê°•/ë§ˆìŒì±™ê¹€/ìƒì‚°ì„±/ê´€ê³„/ìê¸°ì„±ì¥)ë¡œ ìë™ ë¶„ë¥˜í•˜ì—¬, ë§¥ë½ì— ë§ëŠ” ëª…ì–¸ê³¼ ì¹´ë“œë¥¼ ê°€ì±  ë³´ìƒìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ— ì•„í‚¤í…ì²˜ ê°œìš”

```
ì‚¬ìš©ì ë¯¸ì…˜ í…ìŠ¤íŠ¸ ì…ë ¥
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Lucky-Seed ë¶„ë¥˜ ì—”ì§„             â”‚
â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ML íŒŒì´í”„ë¼ì¸   â”‚  â”‚  DL íŒŒì´í”„ë¼ì¸  â”‚  â”‚
â”‚  â”‚  TF-IDF+LogReg  â”‚  â”‚  BiLSTM+Attn  â”‚  â”‚
â”‚  â”‚  (ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸) â”‚  â”‚  (ê³ ì •ë°€ ë¶„ë¥˜)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                      â†“                    â”‚
â”‚              ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ (5 class)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
          í™•ë¥  ê¸°ë°˜ ê°€ì±  ë“±ê¸‰ ê²°ì •
          (Legendary 1% ~ Common 60%)
                       â†“
          ë§¥ë½ ë§¤ì¹­ ëª…ì–¸ + ì¹´ë“œ ë Œë”ë§
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
lucky-seed/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ generate_dataset.py     # í•©ì„± í•œêµ­ì–´ ë¯¸ì…˜ ë°ì´í„°ì…‹ ìƒì„±
â”‚   â”œâ”€â”€ mission_dataset.csv     # ìƒì„±ëœ í•™ìŠµ ë°ì´í„° (~1,000+ samples)
â”‚   â””â”€â”€ quotes.csv              # ì¹´í…Œê³ ë¦¬ë³„ ëª…ì–¸ DB
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ml_classifier.py        # scikit-learn: TF-IDF + LR/RF/SVM
â”‚   â””â”€â”€ dl_classifier.py        # PyTorch: BiLSTM + Self-Attention
â”‚
â”œâ”€â”€ interpretability/
â”‚   â””â”€â”€ shap_analysis.py        # SHAP (ML) + Attention Viz (DL)
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # ì›¹ ë°ëª¨ (3ê°œ íƒ­)
â”‚
â”œâ”€â”€ saved_models/               # í•™ìŠµëœ ëª¨ë¸ íŒŒì¼
â”‚   â”œâ”€â”€ best_ml_model.pkl       # ìµœê³  ì„±ëŠ¥ ML ëª¨ë¸
â”‚   â”œâ”€â”€ logisticregression_model.pkl
â”‚   â”œâ”€â”€ randomforest_model.pkl
â”‚   â”œâ”€â”€ linearsvc_model.pkl
â”‚   â”œâ”€â”€ bilstm_attention.pth    # DL ëª¨ë¸ (PyTorch)
â”‚   â””â”€â”€ tokenizer.json          # ë¬¸ì í† í¬ë‚˜ì´ì €
â”‚
â”œâ”€â”€ assets/                     # ìƒì„±ëœ ì‹œê°í™” ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”œâ”€â”€ dl_training_history.png
â”‚   â”œâ”€â”€ cm_*.png                # í˜¼ë™ í–‰ë ¬
â”‚   â”œâ”€â”€ shap_summary_bar.png
â”‚   â””â”€â”€ attention_examples.png
â”‚
â”œâ”€â”€ train.py                    # í†µí•© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì„¤ì¹˜

```bash
git clone https://github.com/your-username/lucky-seed.git
cd lucky-seed
pip install -r requirements.txt
```

### 2. ëª¨ë¸ í•™ìŠµ

```bash
# ê¸°ë³¸ (30 ì—í¬í¬)
python train.py

# ì»¤ìŠ¤í…€
python train.py --epochs 50 --batch_size 64
```

í•™ìŠµ ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼:
- `saved_models/best_ml_model.pkl` â€” ìµœê³  ì„±ëŠ¥ ML ëª¨ë¸
- `saved_models/bilstm_attention.pth` â€” DL ëª¨ë¸
- `assets/*.png` â€” ì„±ëŠ¥ ì‹œê°í™” ì´ë¯¸ì§€

### 3. ëª¨ë¸ í•´ì„ ì‹¤í–‰

```bash
python interpretability/shap_analysis.py
```

### 4. ì›¹ ë°ëª¨ ì‹¤í–‰

```bash
streamlit run app/streamlit_app.py
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8501` ì ‘ì†

---

## ğŸ¤– ëª¨ë¸ ìƒì„¸

### ML ëª¨ë¸ (scikit-learn)

| ëª¨ë¸ | í•µì‹¬ íŠ¹ì§• | ì¥ì  |
|------|-----------|------|
| **TF-IDF + LogisticRegression** â­ | char n-gram(2-4), sublinear_tf | ë¹ ë¥¸ ì¶”ë¡ , í™•ë¥  ì¶œë ¥, SHAP í˜¸í™˜ |
| TF-IDF + RandomForest | ì•™ìƒë¸” 300 íŠ¸ë¦¬ | ë¹„ì„ í˜• íŒ¨í„´ í¬ì°© |
| TF-IDF + LinearSVC | SVM ë§ˆì§„ ìµœëŒ€í™” | ê³ ì°¨ì› í¬ì†Œ í”¼ì²˜ì— ê°•í•¨ |

**TF-IDF ì„¤ì •:**
- `analyzer="char_wb"`: í˜•íƒœì†Œ ë¶„ì„ ì—†ì´ í•œêµ­ì–´ ì²˜ë¦¬
- `ngram_range=(2, 4)`: 2~4 ë¬¸ì ì‹œí€€ìŠ¤ í”¼ì²˜
- `max_features=10,000`: ìƒìœ„ ë¹ˆë„ íŠ¹ì§•ë§Œ ì„ íƒ

### DL ëª¨ë¸ (PyTorch)

```
BiLSTMAttention
â”œâ”€â”€ Embedding: vocab_size Ã— 64
â”œâ”€â”€ BiLSTM: 64 â†’ 128 (Ã—2, bidirectional) = 256 dim
â”‚   â””â”€â”€ Dropout: 0.3
â”œâ”€â”€ SelfAttention:
â”‚   â”œâ”€â”€ Q, K, V: Linear(256 â†’ 256)
â”‚   â”œâ”€â”€ Scaled Dot-Product: score = QK^T / âˆš256
â”‚   â””â”€â”€ Context: Attention(V).mean(T)
â”œâ”€â”€ LayerNorm(256)
â”œâ”€â”€ FC(256 â†’ 128) â†’ GELU
â”œâ”€â”€ Dropout(0.3)
â””â”€â”€ FC(128 â†’ 5) â†’ Softmax
```

**ì´ íŒŒë¼ë¯¸í„°**: ~ì•½ 450K (ê²½ëŸ‰ ëª¨ë¸)

---

## ğŸ“Š ì„±ëŠ¥ ê¸°ëŒ€ì¹˜

| ëª¨ë¸ | Accuracy | F1 (weighted) | íŠ¹ì´ì‚¬í•­ |
|------|----------|---------------|----------|
| LogisticRegression | ~0.92 | ~0.92 | SHAP í•´ì„ ê°€ëŠ¥ |
| RandomForest | ~0.88 | ~0.88 | ëŠë¦° ì¶”ë¡  |
| LinearSVC | ~0.91 | ~0.91 | í™•ë¥  ë¯¸ì§€ì› |
| **BiLSTM+Attention** | **~0.93** | **~0.93** | Attention ì‹œê°í™” |

*í•©ì„± ë°ì´í„° ê¸°ì¤€; ì‹¤ì œ ì‚¬ìš©ì ë°ì´í„°ë¡œëŠ” ì„±ëŠ¥ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*

---

## ğŸ” ëª¨ë¸ í•´ì„

### SHAP (ML ëª¨ë¸)
- `shap.LinearExplainer`ë¥¼ ì‚¬ìš©í•˜ì—¬ TF-IDF í”¼ì²˜ì˜ ê¸°ì—¬ë„ ë¶„ì„
- ì¹´í…Œê³ ë¦¬ë³„ ìƒìœ„ 15ê°œ íŠ¹ì§• ë°” ì°¨íŠ¸
- ê°œë³„ ì˜ˆì¸¡ ì›Œí„°í´ í”Œë¡¯

### Attention Visualization (DL ëª¨ë¸)
- Scaled Dot-Product Attentionì˜ mean ê°€ì¤‘ì¹˜ë¥¼ ë¬¸ì ë‹¨ìœ„ë¡œ ì‹œê°í™”
- ì–´ë–¤ ë¬¸ì íŒ¨í„´ì´ ë¶„ë¥˜ ê²°ì •ì— ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ ì§ê´€ì ìœ¼ë¡œ í™•ì¸

---

## ğŸ° ê°€ì±  ì‹œìŠ¤í…œ ì„¤ê³„

### ë“±ê¸‰ í™•ë¥ 

| ë“±ê¸‰ | í™•ë¥  | ì´í™íŠ¸ |
|------|------|--------|
| âšª Common | 60% | ê¸°ë³¸ |
| ğŸŸ¢ Uncommon | 25% | ë…¹ìƒ‰ ê¸€ë¡œìš° |
| ğŸ”µ Rare | 10% | íŒŒë€ ê¸€ë¡œìš° |
| ğŸŸ£ Epic | 4% | ë³´ë¼ ê¸€ë¡œìš° |
| ğŸŒŸ Legendary | 1% | ê³¨ë“œ ê¸€ë¡œìš° + ì• ë‹ˆë©”ì´ì…˜ |

### ì‹œë“œ ì „ëµ
```python
seed = int(time.time() * 1000) % 999999  # ms ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„
grade = random.choices(grades, weights=weights, k=1, random_state=seed)
```
"ì´ ë³´ìƒì€ ì˜¤ì§ ì§€ê¸ˆ ì´ ìˆœê°„ì—ë§Œ ì¡´ì¬í•˜ëŠ” ê²°ê³¼"ì„ì„ ê°•ì¡°

---

## ğŸ—‚ ì‚°ì¶œë¬¼ ëª©ë¡

| êµ¬ë¶„ | íŒŒì¼ | ì„¤ëª… |
|------|------|------|
| ML ëª¨ë¸ | `saved_models/best_ml_model.pkl` | pickle ì§ë ¬í™” |
| DL ëª¨ë¸ | `saved_models/bilstm_attention.pth` | PyTorch state_dict |
| í† í¬ë‚˜ì´ì € | `saved_models/tokenizer.json` | ë¬¸ìâ†’ID ë§¤í•‘ |
| ë¹„êµ ì°¨íŠ¸ | `assets/model_comparison.png` | ML vs DL ì„±ëŠ¥ |
| í•™ìŠµ ê³¡ì„  | `assets/dl_training_history.png` | Loss/Acc ì»¤ë¸Œ |
| SHAP | `assets/shap_summary_bar.png` | Feature Importance |
| Attention | `assets/attention_examples.png` | ë¬¸ìë³„ ê°€ì¤‘ì¹˜ |

---

## ğŸ“œ ë¼ì´ì„ ìŠ¤

MIT License

---

## ğŸ‘¤ ì œì‘ì

ì¬ì› ê¹€ (TONY LAMA)
